{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWSAZdXyziQ7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2Mmc4Mv5vE1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chessutils import find_coeffs\n",
    "from boardgen import moirebackground, chessboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOed6L6tmnMp"
   },
   "source": [
    "# Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICLuHwcPl2Z3"
   },
   "outputs": [],
   "source": [
    "PATH_TO_IMG = 'img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4lKjeVRmz0u"
   },
   "outputs": [],
   "source": [
    "IMGSIZE = 480\n",
    "MAXSHEAR = 0.15\n",
    "MINSCALE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjrEWj-_nliW"
   },
   "outputs": [],
   "source": [
    "figimgs = [f for f in os.listdir(PATH_TO_IMG) if f.split('_')[0]=='Chess']\n",
    "figuresimgs = dict()\n",
    "for f in figimgs:\n",
    "    fn = f.split('_')[1].split('4')[0]\n",
    "    img = cv2.imread(os.path.join(PATH_TO_IMG, f))\n",
    "    figuresimgs[fn] = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "figs = ['p', 'b', 'n', 'r', 'q', 'k']\n",
    "colors = ['d', 'l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'numcell':8,\n",
    "    'cellsize':45,\n",
    "    'figures':figs,\n",
    "    'colors':colors,\n",
    "    'shear':MAXSHEAR,\n",
    "    'scale':MINSCALE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 5\n",
    "boardsize = parameters['cellsize'] * parameters['numcell']\n",
    "blank_mask = 255*np.ones((boardsize,boardsize), np.uint8)\n",
    "for i in range(parameters['numcell']*parameters['numcell']):\n",
    "    xp = i % parameters['numcell']\n",
    "    yp = i // parameters['numcell']\n",
    "    if (xp != 0) and (yp != 0):\n",
    "        blank_mask[yp*parameters['cellsize']-NC:yp*parameters['cellsize']+NC,xp*parameters['cellsize']-NC:xp*parameters['cellsize']+NC] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boardmask(imgsize):\n",
    "    boardimage, _, vecs = chessboard(figuresimgs, np.random.rand(13), imgsize, parameters)\n",
    "    background = moirebackground(np.random.rand(8), imgsize)\n",
    "    result = (background * np.asarray(boardimage)).astype(np.uint8)\n",
    "\n",
    "    img = Image.fromarray(blank_mask, 'L')\n",
    "    coeffs = find_coeffs(\n",
    "         vecs.reshape((4,2)),\n",
    "         [(0, 0), (boardsize, 0), (boardsize, boardsize), (0, boardsize)])\n",
    "\n",
    "    img = img.transform((imgsize, imgsize), Image.PERSPECTIVE, coeffs, Image.NEAREST, fillcolor = 'white')\n",
    "    \n",
    "    brd_out = np.expand_dims(result / 255, axis=-1)\n",
    "    msk_out = np.expand_dims(np.asarray(img) / 255, axis=-1)\n",
    "    \n",
    "    return brd_out, msk_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boardmaskgen():\n",
    "    bd, rc = boardmask(IMGSIZE)\n",
    "    yield bd, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBjVMd-K5-PL"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(boardmaskgen,\n",
    "                                         output_signature=\n",
    "                                         (\n",
    "                                          tf.TensorSpec(shape=(IMGSIZE,IMGSIZE,1), dtype=tf.float32),\n",
    "                                          tf.TensorSpec(shape=(IMGSIZE,IMGSIZE,1), dtype=tf.float32)\n",
    "                                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBhM9zBw3EzG"
   },
   "outputs": [],
   "source": [
    "for f in dataset.take(1):\n",
    "    print(f[0].shape, f[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5NJlpr5ahZL"
   },
   "outputs": [],
   "source": [
    "for f in dataset.take(1):\n",
    "    print(np.unique(f[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0YMfgc65-SK"
   },
   "outputs": [],
   "source": [
    "for f in dataset.repeat(20).take(1):\n",
    "    fig, axxes = plt.subplots(ncols=3, nrows=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "    axxes[0].imshow(np.squeeze(f[0]), cmap='gray')\n",
    "    axxes[1].imshow(np.squeeze(f[1]), cmap='gray')\n",
    "    axxes[2].imshow(np.squeeze(f[1]), cmap='gray', alpha=0.5)\n",
    "    axxes[2].imshow(np.squeeze(f[0]), cmap='gray', alpha=0.5)\n",
    "    axxes[0].axis('off')\n",
    "    axxes[1].axis('off')\n",
    "    axxes[2].axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0iFhVjJ04fW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43EDhr2J-Cty"
   },
   "outputs": [],
   "source": [
    "trainset = dataset.repeat().batch(8)\n",
    "valset = dataset.repeat(50).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rgw1gWt53xxV"
   },
   "source": [
    "## UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JIUve3hIvtR"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Dropout, MaxPooling2D, Flatten, Conv2DTranspose, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJfhMMMX52-h"
   },
   "outputs": [],
   "source": [
    "# Encoder Utilities\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, name, kernel_size=3):\n",
    "    '''\n",
    "    Adds 2 convolutional layers with the parameters passed to it\n",
    "\n",
    "    Args:\n",
    "    input_tensor (tensor) -- the input tensor\n",
    "    n_filters (int) -- number of filters\n",
    "    kernel_size (int) -- kernel size for the convolution\n",
    "\n",
    "    Returns:\n",
    "    tensor of output features\n",
    "    '''\n",
    "    # first layer\n",
    "    x = input_tensor\n",
    "    for i in range(2):\n",
    "        x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "                kernel_initializer = 'he_normal', padding = 'same', activation='relu', name=f'{name}_{i}')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(inputs, name, n_filters=64, pool_size=(2,2), dropout=0.3):\n",
    "    '''\n",
    "    Adds two convolutional blocks and then perform down sampling on output of convolutions.\n",
    "\n",
    "    Args:\n",
    "    input_tensor (tensor) -- the input tensor\n",
    "    n_filters (int) -- number of filters\n",
    "    kernel_size (int) -- kernel size for the convolution\n",
    "\n",
    "    Returns:\n",
    "    f - the output features of the convolution block \n",
    "    p - the maxpooled features with dropout\n",
    "    '''\n",
    "\n",
    "    f = conv2d_block(inputs, n_filters=n_filters, name=f'{name}_conv')\n",
    "    p = MaxPooling2D(pool_size=(2,2), name=f'{name}_pool')(f)\n",
    "    p = Dropout(0.3, name=f'{name}_drop')(p)\n",
    "\n",
    "    return f, p\n",
    "\n",
    "\n",
    "def encoder(inputs):\n",
    "    '''\n",
    "    This function defines the encoder or downsampling path.\n",
    "\n",
    "    Args:\n",
    "    inputs (tensor) -- batch of input images\n",
    "\n",
    "    Returns:\n",
    "    p4 - the output maxpooled features of the last encoder block\n",
    "    (f1, f2, f3, f4) - the output features of all the encoder blocks\n",
    "    '''\n",
    "    f1, p1 = encoder_block(inputs, name='enc1', n_filters=32, pool_size=(2,2), dropout=0.3)\n",
    "    f2, p2 = encoder_block(p1, name='enc2', n_filters=64, pool_size=(2,2), dropout=0.3)\n",
    "\n",
    "    return p2, (f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anw13WUf53A9"
   },
   "outputs": [],
   "source": [
    "def bottleneck(inputs):\n",
    "    '''\n",
    "    This function defines the bottleneck convolutions to extract more features before the upsampling layers.\n",
    "    '''\n",
    "\n",
    "    bottle_neck = conv2d_block(inputs, n_filters=128, name='bneck')\n",
    "\n",
    "    return bottle_neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MM41Jg7753Dk"
   },
   "outputs": [],
   "source": [
    "# Decoder Utilities\n",
    "\n",
    "def decoder_block(inputs, conv_output, name, n_filters=64, kernel_size=3, strides=3, dropout=0.3):\n",
    "    '''\n",
    "    defines the one decoder block of the UNet\n",
    "\n",
    "    Args:\n",
    "    inputs (tensor) -- batch of input features\n",
    "    conv_output (tensor) -- features from an encoder block\n",
    "    n_filters (int) -- number of filters\n",
    "    kernel_size (int) -- kernel size\n",
    "    strides (int) -- strides for the deconvolution/upsampling\n",
    "    padding (string) -- \"same\" or \"valid\", tells if shape will be preserved by zero padding\n",
    "\n",
    "    Returns:\n",
    "    c (tensor) -- output features of the decoder block\n",
    "    '''\n",
    "    u = Conv2DTranspose(\n",
    "      n_filters,\n",
    "      kernel_size, \n",
    "      strides=strides,\n",
    "      padding='same', name=f'{name}_trans')(inputs)\n",
    "    c = Concatenate(name=f'{name}_conc')([u, conv_output])\n",
    "    c = Dropout(dropout, name=f'{name}_drop')(c)\n",
    "    c = conv2d_block(c, n_filters, name=f'{name}_conv', kernel_size=3)\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def decoder(inputs, convs):\n",
    "    '''\n",
    "    Defines the decoder of the UNet chaining together 4 decoder blocks. \n",
    "\n",
    "    Args:\n",
    "    inputs (tensor) -- batch of input features\n",
    "    convs (tuple) -- features from the encoder blocks\n",
    "\n",
    "    Returns:\n",
    "    outputs (tensor) -- the pixel wise label map of the image\n",
    "    '''\n",
    "\n",
    "    f1, f2 = convs\n",
    "\n",
    "    c8 = decoder_block(inputs, f2, name='dec2', n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=0.3)\n",
    "    c9 = decoder_block(c8, f1, name='dec3', n_filters=32, kernel_size=(3,3), strides=(2,2), dropout=0.3)\n",
    "\n",
    "    outputs = Conv2D(2, (1, 1), activation='softmax', name='finalb')(c9)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O140S-z9-c_6"
   },
   "outputs": [],
   "source": [
    "def unet():\n",
    "    '''\n",
    "    Defines the UNet by connecting the encoder, bottleneck and decoder.\n",
    "    '''\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(IMGSIZE,IMGSIZE,1))\n",
    "    encoder_output, convs = encoder(inputs)\n",
    "    bottle_neck = bottleneck(encoder_output)\n",
    "    outputs = decoder(bottle_neck, convs)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='unet_board')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00DcBPbj5vHg"
   },
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTTXBHkhZAuw"
   },
   "outputs": [],
   "source": [
    "# configure the optimizer, loss and metrics for training\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABAVJTHk6e3s"
   },
   "outputs": [],
   "source": [
    "# configure the training parameters and train the model\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "model_history = model.fit(trainset,\n",
    "                          steps_per_epoch=200,\n",
    "                          epochs=EPOCHS,\n",
    "                          validation_data=valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuDH9ihV6e9T"
   },
   "outputs": [],
   "source": [
    "for g in valset.take(1):\n",
    "    fig, axx = plt.subplots(nrows=1, ncols=3, figsize=(15,5), sharey=True)\n",
    "    axx[0].imshow(np.squeeze(g[0].numpy()), cmap='gray')\n",
    "    axx[0].axis('off')\n",
    "    axx[1].imshow(g[1].numpy()[0,:,:,0], cmap='gray')\n",
    "    axx[1].axis('off')\n",
    "    pred = np.squeeze(model.predict(g[0]))\n",
    "    b = np.argmax(pred[:,:,0:2], axis=-1)\n",
    "    axx[2].imshow(np.squeeze(g[0].numpy()), cmap='gray', alpha=0.5)\n",
    "    axx[2].imshow(b, cmap='gray', alpha=0.5)\n",
    "    axx[2].axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcBRwftA6e_7"
   },
   "outputs": [],
   "source": [
    "model.save('models/unet_board_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJWjEY8lHHBu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO5UUaqHxiNfNJkyb0iPfBI",
   "collapsed_sections": [],
   "name": "board.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
